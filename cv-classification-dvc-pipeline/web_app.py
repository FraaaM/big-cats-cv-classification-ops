import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms
from PIL import Image
import yaml
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# !!! –î–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã 
# –≤—ã–ø–æ–ª–Ω–∏—Ç—å –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ streamlit run app.py

NAME_MAPPING = {
    'Panthera leo': '–õ–µ–≤',
    'Panthera tigris': '–¢–∏–≥—Ä',
    'Panthera onca': '–Ø–≥—É–∞—Ä',
    'Panthera pardus': '–õ–µ–æ–ø–∞—Ä–¥',
    'Panthera uncia': '–ò—Ä–±–∏—Å (–°–Ω–µ–∂–Ω—ã–π –±–∞—Ä—Å)'
}

def get_common_name(scientific_name):
    clean_name = scientific_name.replace("_", " ")
    return NAME_MAPPING.get(clean_name, clean_name)


st.set_page_config(
    page_title="Big Cats Vision",
    page_icon="ü¶Å",
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_data
def load_params():
    if os.path.exists("params.yaml"):
        with open("params.yaml", "r") as f:
            return yaml.safe_load(f)
    return None

PARAMS = load_params()

if PARAMS:
    MODEL_PATH = PARAMS['train']['model_path']
    IMG_SIZE = PARAMS['base']['img_size']
    DATA_DIR = PARAMS['data']['images_dir']
else:
    st.error("–§–∞–π–ª params.yaml –Ω–µ –Ω–∞–π–¥–µ–Ω! –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
    MODEL_PATH = "models/best_model.pth"
    IMG_SIZE = 224
    DATA_DIR = "data/dataset_images"

FALLBACK_CLASSES = [
    'Panthera leo', 
    'Panthera onca', 
    'Panthera pardus', 
    'Panthera tigris', 
    'Panthera uncia'
]


@st.cache_data
def get_classes(data_dir):
    if os.path.exists(data_dir):
        classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])
        if classes:
            return classes
    return sorted(FALLBACK_CLASSES)

@st.cache_resource
def load_model(model_path, num_classes):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    try:
        model = models.efficientnet_v2_s(weights=None)
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(in_features, num_classes)
        
        if not os.path.exists(model_path):
            return None, f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}"
            
        map_location = torch.device('cpu')
        model.load_state_dict(torch.load(model_path, map_location=map_location))
        model.to(device)
        model.eval()
        return model, None
    except Exception as e:
        return None, str(e)

def preprocess_image(image, img_size):
    transform = transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    return transform(image).unsqueeze(0)

# --- –û—Å–Ω–æ–≤–Ω–æ–π —ç–∫—Ä–∞–Ω ---
st.sidebar.title("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
st.sidebar.info(
    """
    –≠—Ç–æ –¥–µ–º–æ-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–æ–≤ –±–æ–ª—å—à–∏—Ö –∫–æ—à–µ–∫ (Panthera).
    
    **–ú–æ–¥–µ–ª—å:** EfficientNet V2 Small
    **–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö:** iNaturalist
    """
)

st.sidebar.write("---")
confidence_threshold = st.sidebar.slider("–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (%)", 0, 100, 50)

st.title("ü¶Å Panthera Vision AI")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ **–õ—å–≤–∞, –¢–∏–≥—Ä–∞, –Ø–≥—É–∞—Ä–∞, –õ–µ–æ–ø–∞—Ä–¥–∞ –∏–ª–∏ –ò—Ä–±–∏—Å–∞**, –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –≤–∏–¥.")

classes = get_classes(DATA_DIR)
# st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–ª–∞—Å—Å–æ–≤: {len(classes)}") # –î–µ–±–∞–≥

model, error_msg = load_model(MODEL_PATH, len(classes))

if model is None:
    st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {error_msg}")
    st.warning("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∑–∞–ø—É—Å—Ç–∏–ª–∏ `dvc repro` –∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
    st.stop()

uploaded_file = st.file_uploader("–ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—é–¥–∞...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    col1, col2 = st.columns([1, 1])
    
    image = Image.open(uploaded_file).convert('RGB')
    with col1:
        st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ —Ñ–æ—Ç–æ', use_container_width=True)

    with col2:
        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞")
        
        with st.spinner('–í –ø—Ä–æ—Ü–µ—Å—Å–µ...'):
            device = next(model.parameters()).device
            input_tensor = preprocess_image(image, IMG_SIZE).to(device)
            
            with torch.no_grad():
                outputs = model(input_tensor)
                probs = F.softmax(outputs, dim=1)[0]
            
            top_prob, top_idx = torch.topk(probs, 1)
            confidence = top_prob.item() * 100
            pred_class = get_common_name(classes[top_idx.item()])

        if confidence < confidence_threshold:
            st.warning(f"‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ({confidence:.2f}%)")
            st.write(f"–ú–æ–¥–µ–ª—å —Å–∫–ª–æ–Ω—è–µ—Ç—Å—è –∫ **{pred_class}**, –Ω–æ –Ω–µ —É–≤–µ—Ä–µ–Ω–∞.")
        else:
            if confidence > 90:
                st.success(f"üéØ –≠—Ç–æ —Ç–æ—á–Ω–æ **{pred_class}**!")
            elif confidence > 75:
                st.info(f"‚úÖ –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —ç—Ç–æ **{pred_class}**.")
            else:
                st.info(f"ü§î –í–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ **{pred_class}**.")
            
            st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", f"{confidence:.2f}%")

        st.write("---")
        st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:**")
        
        top5_prob, top5_idx = torch.topk(probs, min(5, len(classes)))
        probs_np = top5_prob.cpu().numpy() * 100
        
        classes_np = [get_common_name(classes[idx]) for idx in top5_idx.cpu().numpy()]
        
        df_probs = pd.DataFrame({
            '–í–∏–¥': classes_np,
            '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (%)': probs_np
        })
        
        st.bar_chart(df_probs.set_index('–í–∏–¥'), color="#4CAF50")

        with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ"):
            st.dataframe(df_probs.style.format({"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (%)": "{:.2f}"}))